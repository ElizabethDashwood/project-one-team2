{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13b24f10-4e47-4f0d-985c-4bf117aeb04f",
   "metadata": {},
   "source": [
    "# Importing the House Price data from the Melbourne City Database (API)\n",
    "(VB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e83952-f592-4909-a188-1bc2c28afc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b2dcad-6f54-419a-810f-6c4beb1fba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base URL for API\n",
    "base_url = \"https://data.melbourne.vic.gov.au/api/explore/v2.1/catalog/datasets/house-prices-by-small-area-sale-year/records?limit=50&refine=sale_year%3A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89df5a07-0d10-434f-b62a-5017b481315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all years\n",
    "min_year = 2000 - 1\n",
    "max_year = 2016\n",
    "temp = []\n",
    "\n",
    "for i in range(max_year, min_year, -1):\n",
    "    response = requests.get(base_url + str(i)).json()\n",
    "\n",
    "    year_results = response[\"results\"]\n",
    "\n",
    "    for j in range(len(year_results)):\n",
    "        temp.append(year_results[j])\n",
    "    \n",
    "house_price_df = pd.DataFrame(temp)\n",
    "house_price_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aea52d-6847-4c50-80e9-0ab587c2bbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from DF\n",
    "house_price_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca5abb9-f47c-4251-9ccf-08f45d3bccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NA data\n",
    "house_price_df = house_price_df.dropna(how='any')\n",
    "house_price_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024eb030-5fe5-462f-aefc-cc9a9a82fb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display clean DF\n",
    "house_price_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367225d7-f34e-4c7e-8376-d93ffda74308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique small areas\n",
    "print(house_price_df[\"small_area\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb36dee-3085-4d58-b58b-f49e1187056c",
   "metadata": {},
   "source": [
    "# Modifying house_price_df for 2 year ranges, to compare with Income Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77944876-2f23-404f-acdf-a73eb32b4751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying house_price_df for 2 year ranges, to compare with Income Data\n",
    "starting_years = list(range(2003,2015 + 1,2))\n",
    "\n",
    "# empty list to store new dictionaries\n",
    "median_price_two_year_dict = {}\n",
    "sum_transactions_two_year_dict = {}\n",
    "\n",
    "# loop through year ranges\n",
    "for year in starting_years:\n",
    "    st_year = house_price_df[house_price_df[\"sale_year\"] == str(year)]\n",
    "    en_year = house_price_df[house_price_df[\"sale_year\"] == str(year + 1)]\n",
    "\n",
    "    # get intersection\n",
    "    two_year = pd.merge(st_year, en_year, how ='inner', on =['small_area', 'type'])\n",
    "\n",
    "    # get rid of \"Docklands House/Townhouse\" and \"Southbank House/Townhouse\"\n",
    "    two_year = two_year.drop(two_year[(two_year['small_area'] == 'Docklands') & (two_year['type'] == 'House/Townhouse')].index)\n",
    "    two_year = two_year.drop(two_year[(two_year['small_area'] == 'Southbank') & (two_year['type'] == 'House/Townhouse')].index)\n",
    "    two_year = two_year.reset_index(drop=True)\n",
    "\n",
    "    # add together transaction counts, and average median prices\n",
    "    average_median_2y = (two_year[\"median_price_x\"] + two_year[\"median_price_y\"])/2\n",
    "    two_year[\"average_median_2y\"] = average_median_2y\n",
    "    sum_transactions_2y = two_year[\"transaction_count_x\"] + two_year[\"transaction_count_y\"]\n",
    "    two_year[\"sum_transactions_2y\"] = sum_transactions_2y\n",
    "\n",
    "    # split into types\n",
    "    two_year_groupby = two_year.groupby([\"type\"])\n",
    "    two_year_ave_median = two_year_groupby[\"average_median_2y\"].mean()\n",
    "    two_year_sum_transactions = two_year_groupby[\"sum_transactions_2y\"].mean()\n",
    "\n",
    "    # put into dictionaries\n",
    "    median_price_two_year_dict[f\"%s-%s\" % (year, year + 1)] = two_year_ave_median\n",
    "    sum_transactions_two_year_dict[f\"%s-%s\" % (year, year + 1)] = two_year_sum_transactions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060626ba-54de-4f74-803b-88c457b81138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# median price DF\n",
    "median_price_two_year_df = pd.DataFrame(median_price_two_year_dict)\n",
    "median_price_two_year_df.head(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972578c7-9963-49c9-ba3d-c14dda2d038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of transactions DF\n",
    "sum_transactions_two_year_df = pd.DataFrame(sum_transactions_two_year_dict)\n",
    "sum_transactions_two_year_df.head(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8565311-d680-4f0f-8357-04b10083e6a3",
   "metadata": {},
   "source": [
    "# Importing the Household Income data from the ABS\n",
    "(LM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4928ee-97bf-46a4-aa10-91dfe6214f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your Excel file\n",
    "household_income_data = \"Resources/5204055011do001.xlsx\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eba56b-cdd3-4130-8c7a-e1f8a5399f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the row indices to skip\n",
    "rows_to_skip = list(range(0, 6)) + [7] + list(range(9, 26)) + list(range(27, 40)) + list(range(42, 127))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9e4763-6776-4ffa-9014-5006cc937d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ABS income data file and store into Pandas DataFrames\n",
    "dfs = pd.read_excel(household_income_data, sheet_name=None, skiprows=rows_to_skip)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac9e75c-7c37-49a0-998e-d9d8910f5428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store DataFrames with tab names as a column\n",
    "dfs_with_tab_name = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34386d24-ae28-4878-b8b0-087d5a0772af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag to skip the first and last tab\n",
    "skip_first_tab = True\n",
    "skip_last_tab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf11f40-b491-48a7-8333-7447a37cbd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each sheet in the dictionary\n",
    "for sheet_name, df in dfs.items():\n",
    "    if skip_first_tab:\n",
    "        skip_first_tab = False\n",
    "        continue  # Skip processing the first tab\n",
    "        \n",
    "    if skip_last_tab:\n",
    "        break  # Exit the loop if the last tab is reached\n",
    "        \n",
    "    # Determine the column indices dynamically based on the actual number of columns\n",
    "    num_cols = min(7, len(df.columns))\n",
    "    \n",
    "    # Ensure we don't exceed the number of columns in the DataFrame\n",
    "    columns_to_read = list(range(num_cols))\n",
    "    \n",
    "    # Select only the specified columns\n",
    "    df_selected = df.iloc[:, columns_to_read].copy()\n",
    "    \n",
    "    # Add a new column with the tab name to the selected DataFrame using loc\n",
    "    df_selected.loc[:, 'Year/s'] = sheet_name\n",
    "    \n",
    "    # Append the modified DataFrame to the list\n",
    "    dfs_with_tab_name.append(df_selected)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295938b6-8dbd-48fd-9f5f-bce76aa564da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "combined_df = pd.concat(dfs_with_tab_name, ignore_index=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e7a2cd-e520-4718-8bb8-c3993984e9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to map old values to new values\n",
    "value_mapping = {'Table 1.1': '2003-2004', 'Table 1.2': '2005-2006', 'Table 1.3': '2007-2008', 'Table 1.4': '2009-2010', 'Table 1.5': '2011-2012', 'Table 1.6': '2013-2014', 'Table 1.7': '2015-2016', 'Table 1.8': '2017-2018', 'Table 1.9': '2019-2020', 'Table 1.10': '2020-2021', 'Table 1.11': '2021-2022', 'Explanatory Notes': '', 'tab_name': 'Year/s'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430bb218-fba5-44ce-8f71-033a7c872261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values in column 'tab_name' using the value_mapping dictionary\n",
    "combined_df['Year/s'] = combined_df['Year/s'].replace(value_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629d79ef-157e-4596-88fc-d042732663d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where column 'Year/s' has value '2020-2021' or '2021-2022'\n",
    "values_to_remove = ['2020-2021', '2021-2022']\n",
    "cleaned_df = combined_df[~combined_df['Year/s'].isin(values_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8379a6e0-99e2-4886-9244-c8d25ba99eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert values to numeric data type\n",
    "cleaned_df.loc[:, 'Wages and salaries'] = cleaned_df['Wages and salaries'].astype(float)\n",
    "cleaned_df.loc[:, 'Income from  unincorporated business (a)'] = cleaned_df['Income from  unincorporated business (a)'].astype(float)\n",
    "cleaned_df.loc[:, 'Property income and superannuation'] = cleaned_df['Property income and superannuation'].astype(float)\n",
    "cleaned_df.loc[:, 'Government pensions and allowances'] = cleaned_df['Government pensions and allowances'].astype(float)\n",
    "cleaned_df.loc[:, 'Other'] = cleaned_df['Other'].astype(float)\n",
    "cleaned_df.loc[:, 'All households (b)'] = cleaned_df['All households (b)'].astype(float)\n",
    "cleaned_df.loc[:, 'Year/s'] = cleaned_df['Year/s'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a35064-014c-4c83-9acf-7ef8b5a7ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path for the CSV file\n",
    "csv_file_path = 'ABS_income_data.csv'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4028d6e5-4200-496d-ac88-1383faf42bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "cleaned_df.to_csv(csv_file_path, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac8c657-ea59-4030-a99f-b6e21402dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"DataFrame successfully saved to '{csv_file_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be866ddd-8537-4d95-9810-ea2a03caefe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table with 'Category' as rows, 'Year' as columns, and 'Value' as values\n",
    "pivot_df = cleaned_df.pivot_table(columns='Year/s', values='All households (b)', aggfunc='sum')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775ff2f-699a-4c9c-8cda-4231d93c3917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the index as \"Household income\"\n",
    "pivot_df = cleaned_df.pivot_table(index='Unnamed: 0', columns='Year/s', values='All households (b)', aggfunc='sum')\n",
    "pivot_df = pivot_df.rename_axis('Household income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d92a63a-2ee9-413f-b89c-e57d3f633ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "household_income_df = pivot_df\n",
    "household_income_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaa0ee4-159b-4e49-80b1-f6a4f06b4443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the DataFrame to swap rows and columns\n",
    "transposed_df = cleaned_df.T.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183f4a36-f98e-4836-8d8e-4846fa5b6eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the transposed DataFrame to include the rows with income categories based on a specific column\n",
    "income_comparison_df = transposed_df[transposed_df['index'].isin(['Gross Disposable Income', 'Total Gross Income', 'Total Income Payable'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552c2b73-520e-4e0e-8569-ceee702e5368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the 'Year' column as the index\n",
    "income_comparison_df.set_index('index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f067fa-360b-4004-9da7-d7a4ae64608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'index' column after setting it as the index\n",
    "income_comparison_df.drop(columns='index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b748c7-c852-4c8c-8a5c-293e851073d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the line graph\n",
    "income_comparison_df.T.plot(kind='line', marker='o', figsize=(12, 6))\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Income')\n",
    "plt.title('Comparison of Income Categories Over the Years')\n",
    "plt.legend(title='Income Category')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ba1d7c-a681-44a8-9b1b-f24b649aa550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the DataFrame to swap rows and columns\n",
    "transposed_df = cleaned_df.T.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b22e38-5aaf-46dc-b7d3-fcd03d80eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the transposed DataFrame to include the rows with income categories based on a specific column\n",
    "income_comparison_df = transposed_df[transposed_df['index'].isin(['Gross Disposable Income', 'Total Gross Income', 'Total Income Payable'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5d8d3a-fd53-4ea8-906a-dc01c42a7d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the 'index' column as the index for the DataFrame\n",
    "income_comparison_df.set_index('index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc389e9-ea07-47c6-a4e1-e6c2cb17eacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the column by position after setting it as the index\n",
    "income_comparison_df = income_comparison_df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5faf2cf-9169-42f1-a648-4ffd67e719b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the line graph\n",
    "income_comparison_df.T.plot(kind='line', marker='o', figsize=(12, 6))\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Income')\n",
    "plt.title('Comparison of Income Categories Over the Years')\n",
    "plt.legend(title='Income Category')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c039b0f2-16d1-4d60-93be-a92e041f2fa5",
   "metadata": {},
   "source": [
    "# Importing the Population and Suburb data from the ABS\n",
    "(ED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b69aa6-8ae2-4d80-9f48-d9865e1b67e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files to Load\n",
    "population_data_to_load_2021 = (\"../Project_1/2021_GCP_SAL_for_VIC_short-header/2021 Census GCP Suburbs and Localities for VIC/2021Census_G03_VIC_SAL.csv\")\n",
    "suburb_name_data_to_load_2021 = (\"../Project_1/2021_GCP_SAL_for_VIC_short-header/Metadata/2021Census_geog_desc_1st_2nd_3rd_release.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2051f900-446d-4e4f-bd90-b1f6c546204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Population data into Pandas DataFrames\n",
    "population_data_2021_df = pd.read_csv(population_data_to_load_2021)\n",
    "\n",
    "# Read population and Suburb data into Pandas DataFrames and specifiy which worksheet number to be read in suburb file\n",
    "sheet_name = 0\n",
    "suburb_name_data_2021_df = pd.read_excel(\"../Project_1/2021_GCP_SAL_for_VIC_short-header/Metadata/2021Census_geog_desc_1st_2nd_3rd_release.xlsx\", sheet_name = 5)\n",
    "# Reference:https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dd35af-5aa5-424a-98b1-a018a4167762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test only: Check data load for suburb data\n",
    "suburb_name_data_2021_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba61b738-29e4-4225-aa9d-de2e6e874a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column in Population data for allow DataFrames to merge\n",
    "population_data_2021_df= population_data_2021_df.rename(columns={\"SAL_CODE_2021\":\"Census_Code_2021\"})\n",
    "population_data_2021_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99784ff1-1f1d-4ec5-b7ca-a4838938e9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Population Data and Suburb Data DataFrames\n",
    "population_and_suburb_merged_df = pd.merge(population_data_2021_df, suburb_name_data_2021_df, how = \"left\", on=[\"Census_Code_2021\", \"Census_Code_2021\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92487e18-dbf6-4a55-8b36-071c1ee81e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Index to AGSS_Code_2021 and rename columns to meaningful headings\n",
    "population_and_suburb_data_df = population_and_suburb_merged_df.set_index([\"AGSS_Code_2021\"])\n",
    "population_and_suburb_data_df = population_and_suburb_data_df.rename(columns={\"Total_Total\":\"Total_Population\",\"Census_Name_2021\":\"Suburb_Name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b84767-4879-40fe-9fcb-26e163fbd956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final DataFrame with only the required columns\n",
    "population_and_suburb_df = population_and_suburb_data_df[[\"Census_Code_2021\",\"Suburb_Name\",\"Total_Population\",\"Area sqkm\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed1844-0abd-477b-aa62-5717ae15f5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test only: Check final DataFrame with required columns\n",
    "population_and_suburb_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
